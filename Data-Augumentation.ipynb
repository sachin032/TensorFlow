{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Augmentation and how does it helps?\n",
    "**Data augmentation** is a technique to increase the size and variation in a given dataset.\n",
    "It is a well known fact that **Deep Neural Nets** work best if Dataset is huge in both size and variety.\n",
    "\n",
    "Other Augumentation techniques which can be at root of such exploration is **SMOTE.**\n",
    "\n",
    "\n",
    "This notebook will cover the aspect of Data Augumentation over Image Data.\n",
    "Focus will be on **Various techniques** to achieve **Data augmentation** \n",
    "\n",
    "\n",
    "we will be using **Tensorflow** and **Keras** for implementation which will help us to understand the various aspect of the field.\n",
    "\n",
    "More often when data is less in size of not having variety in it, Including **Data augmentation** in **Data preprocessing** steps, help producing larger amount of data with good amount of variety in it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T18:53:06.849875Z",
     "start_time": "2020-02-01T18:53:05.177658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "## Bare minimum library requirement\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "#Keras provide API for Augmentation helps in generation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T18:19:17.319497Z",
     "start_time": "2020-02-01T18:17:56.003301Z"
    }
   },
   "outputs": [],
   "source": [
    "# # #Horse-or-Human\n",
    "# !wget --no-check-certificate \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\" \\-O \"/tmp/horse-or-human.zip\"\n",
    "\n",
    "# #validation data for Horse-or-Human\n",
    "# !wget --no-check-certificate \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\" \\-O \"/tmp/validation-horse-or-human.zip\"\n",
    "\n",
    "#Cats vs Dogs\n",
    "# !wget --no-check-certificate \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\" \\-O \"/tmp/cats_and_dogs_filtered.zip\"\n",
    "\n",
    "#Cats-V-Dogs data from microsoft \n",
    "# !wget --no-check-certificate \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\-O \"/tmp/cats-and-dogs.zip\"\n",
    "\n",
    "\n",
    "# #Happy or sad\n",
    "# !wget --no-check-certificate \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\-O \"/tmp/happy-or-sad.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T18:53:23.361660Z",
     "start_time": "2020-02-01T18:53:13.590431Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "local_zip = \"/tmp/cats-and-dogs.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(\"/tmp/\")\n",
    "zip_ref.close()\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir('/tmp/cats-v-dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T18:53:23.422344Z",
     "start_time": "2020-02-01T18:53:23.407450Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "###############################################\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T18:53:41.325215Z",
     "start_time": "2020-02-01T18:53:23.471987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666.jpg is zero length, so ignoring.\n",
      "11702.jpg is zero length, so ignoring.\n"
     ]
    }
   ],
   "source": [
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine the situation that we have to assign a category to an image that it is a **cat** or **dog** is in the image.\n",
    "and in our sample data set, we have got such images where we have several cars lined up one after another.\n",
    "\n",
    "Now how can we play with such images on the fly before giving them to model to get trained on.\n",
    "Better augment them on the fly and produce a batch of tensors.\n",
    "\n",
    "Doing the augmentation using **Keras** gives another upper hand to us, It doesn't modify or affect the original data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T18:53:41.453724Z",
     "start_time": "2020-02-01T18:53:41.396851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cat iamge count ::  12501\n",
      "Total Dog iamge count ::  12501\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Cat iamge count :: \",len(os.listdir('/tmp/PetImages/Cat/')))\n",
    "print(\"Total Dog iamge count :: \",len(os.listdir('/tmp/PetImages/Dog/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T18:53:55.637906Z",
     "start_time": "2020-02-01T18:53:55.467947Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imread, imshow, subplots, show\n",
    "CAT_TRAINING_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
    "DOG_TRAINING_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "pic_index += 8\n",
    "\n",
    "next_cat_pix = [os.path.join(CAT_TRAINING_DIR, fname) for fname in os.listdir('/tmp/PetImages/Cat/')[pic_index - 8:pic_index]]\n",
    "next_dog_pix = [os.path.join(DOG_TRAINING_DIR, fname) for fname in os.listdir('/tmp/PetImages/Dog/')[pic_index - 8:pic_index]]\n",
    "\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix + next_dog_pix):\n",
    "    # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off')  # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's generate an UDF which would be helpful in plotting the various augmentated images from the source image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:07.003788Z",
     "start_time": "2020-01-30T11:22:06.995918Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def plot(data_generator):\n",
    "    \"\"\"\n",
    "    Plots 4 images generated by an object of the ImageDataGenerator class.\n",
    "    \"\"\"\n",
    "    data_generator.fit(images)\n",
    "    image_iterator = data_generator.flow(images)\n",
    "\n",
    "    # Plot the images given by the iterator\n",
    "    fig, rows = subplots(nrows=1, ncols=4, figsize=(18, 18))\n",
    "    for row in rows:\n",
    "        row.imshow(image_iterator.next()[0].astype('int'))\n",
    "        row.axis('off')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Do some basic augmentation and later we will apply various permutation and combination of these techniques. **Lets start with image rotation by few degrees so that features(Pixel values based on spatial arrangement) get affected and label unaffected.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:07.232156Z",
     "start_time": "2020-01-30T11:22:07.005108Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = plt.imread(\"h1.jpeg\")\n",
    "# Creating a dataset which contains just one image.\n",
    "images = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "imshow(images[0])\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:08.000758Z",
     "start_time": "2020-01-30T11:22:07.233526Z"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rotation_range=180)\n",
    "plot(data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few examples regarding how image augmentation looked like before going to model for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:08.868289Z",
     "start_time": "2020-01-30T11:22:08.002770Z"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(featurewise_center=False,\n",
    "                                    width_shift_range=0.65)\n",
    "plot(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:09.965614Z",
     "start_time": "2020-01-30T11:22:08.871915Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(zoom_range=[1, 2], rotation_range=260)\n",
    "plot(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:10.803694Z",
     "start_time": "2020-01-30T11:22:09.967560Z"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(width_shift_range=[0.1, 0.5])\n",
    "plot(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:11.734852Z",
     "start_time": "2020-01-30T11:22:10.805549Z"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(horizontal_flip=True,\n",
    "                                    zoom_range=[1, 1.5],\n",
    "                                    width_shift_range=0.2)\n",
    "plot(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:12.656938Z",
     "start_time": "2020-01-30T11:22:11.738823Z"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(vertical_flip=True,\n",
    "                                    zoom_range=[0.2, 0.9],\n",
    "                                    width_shift_range=0.2)\n",
    "plot(data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's examine the scenario where augmentation before training can help better at prediction time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset we are going to use in this experiment is to detect wether given image is a human or horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:13.724588Z",
     "start_time": "2020-01-30T11:22:12.658520Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "#Unizip Training data\n",
    "train_path = \"/tmp/horse-or-human.zip\"\n",
    "zip_ref = zipfile.ZipFile(train_path, 'r')\n",
    "zip_ref.extractall(\"/tmp/horse-or-human\")\n",
    "zip_ref.close()\n",
    "print(\"Train data unzipped successfully\")\n",
    "training_data_path = \"/tmp/horse-or-human/\"\n",
    "\n",
    "#Unzip validation data\n",
    "validation_path = \"/tmp/validation-horse-or-human.zip\"\n",
    "zip_ref = zipfile.ZipFile(validation_path, 'r')\n",
    "zip_ref.extractall(\"/tmp/validation-horse-or-human\")\n",
    "zip_ref.close()\n",
    "print(\"Validation data unzipped successfully\")\n",
    "validation_data_path = \"/tmp/validation-horse-or-human/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data, we unzipped the corpus and there exist two sub directories named **human** and **horses.**\n",
    "<br>\n",
    "**Let's check the number of images available for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:13.733560Z",
     "start_time": "2020-01-30T11:22:13.726239Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for directory in os.listdir(training_data_path):\n",
    "    count = 0\n",
    "    for fileName in os.listdir(training_data_path + directory):\n",
    "        count += 1\n",
    "\n",
    "    dict.update({\"{0}\".format(directory): count})\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result it is clear that it does not matter if we chose any kinda Neural nets to train a binary classifier\n",
    "it will be a weak model to give accurate prediction.\n",
    "Training on such less data will also lead to **Overfitting** of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the callback mechanism to have a hooked checpoint mechanism over training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:13.754031Z",
     "start_time": "2020-01-30T11:22:13.736073Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.99):\n",
    "            print(\n",
    "                \"\\n\\n\\nGot accuracy above 0.99% so cancelling any further training! \\n\\nas it might cause Overfitting\\n\\n\"\n",
    "            )\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:22:13.770580Z",
     "start_time": "2020-01-30T11:22:13.757007Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    '''\n",
    "    Responsible for Neural net skeleton\n",
    "    '''\n",
    "    '''\n",
    "    Sequential design of layering to interconnect various layers.\n",
    "    Hawk eye view would be\n",
    "     ___________________________________________________\n",
    "    |conv-->pool-->conv-->pool-->flatten-->dense-->dense|\n",
    "     ---------------------------------------------------\n",
    "    \n",
    "    #Basic parameters to be passed on call \n",
    "    #1.training_data_path\n",
    "    #2.validation_data_path\n",
    "    #3.callback\n",
    "    #4.epochs\n",
    "    #5.batch_size\n",
    "    #6.learning_rate\n",
    "    \n",
    "    '''\n",
    "    def neuralModeling(self, training_data_path, validation_data_path,\n",
    "                       callback, epochs, batch_size, learning_rate):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(16, (3, 3),\n",
    "                                   activation='relu',\n",
    "                                   input_shape=(150, 150, 3)),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        #Model compilation\n",
    "        model.compile(\n",
    "            optimizer=RMSprop(lr=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        #model summary\n",
    "        model.summary()\n",
    "\n",
    "        #Make datagen for Train generator\n",
    "        train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "        #Train generator\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            training_data_path,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "        #Make datagen for validation generator\n",
    "        validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "        #validation generator\n",
    "        validation_generator = validation_datagen.flow_from_directory(\n",
    "            validation_data_path,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                            validation_data=validation_generator,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            callbacks=[callback])\n",
    "\n",
    "        return history, model\n",
    "\n",
    "    '''\n",
    "    initialize the basic information    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        print(\"Object getting created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**Let's start the training the model and then run some image prediction directly from Google.com**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T11:28:49.077497Z",
     "start_time": "2020-01-30T11:22:13.772318Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "history, model = net.neuralModeling(training_data_path, validation_data_path,\n",
    "                                    callback, 20, 5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T06:49:56.773406Z",
     "start_time": "2020-01-31T06:49:56.345781Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "# plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "loss\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T06:43:13.414850Z",
     "start_time": "2020-01-31T06:43:13.405165Z"
    }
   },
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T09:22:26.067595Z",
     "start_time": "2020-01-30T09:22:26.063847Z"
    }
   },
   "source": [
    "***Data augmentation does many changes on the fly in every image and makes a batch  before training to model.That is one of the prime reason that model training with data augmentation on is slower but effective.***\n",
    "\n",
    "<br><br>\n",
    "\n",
    "                                ----** The End **----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1549px",
    "right": "20px",
    "top": "122px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
